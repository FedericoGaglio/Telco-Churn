{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/Telco-Customer-Churn.train.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizzo il dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vedo le chiavi presenti nel database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in dataset.columns:\n",
    "    print(\"Colonna:\"+el+\"\",dataset[el].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.TotalCharges.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= dataset.replace(' ', np.NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vado a buttare le poche righe che presentano dei valori nulli nella colonna \"TotalCharges\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna()\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per poter lavorare in comodità vado a separare i valori categorici da quelli numerico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_numeriche = dataset.select_dtypes(include = np.number)\n",
    "features_numeriche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_categoriche = dataset.select_dtypes(include = 'object')\n",
    "features_categoriche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding\n",
    "\n",
    "Vado ad utilizzare il label encoder per trasformare i dati categorici del dataset(di tipo 'object') in valori interi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for i in features_categoriche:\n",
    "    features_categoriche[i] = label_encoder.fit_transform(features_categoriche[i])\n",
    "    \n",
    "features_categoriche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vado a ricompattare i dati che precedentemente avevo separato in numerici e categorici, nel dataset intero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDatasetNumCat = pd.concat([features_numeriche, features_categoriche], axis = 1)\n",
    "\n",
    "fullDatasetNumCat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separo il target dal resto dei dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = fullDatasetNumCat.Churn\n",
    "\n",
    "X = fullDatasetNumCat.drop(columns=['Churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Selection\n",
    "\n",
    "Per andare a semplicare il modello ed evitare un eccessivo overfitting vado ad utilizzare, per la scelta di un sottoinsieme dei vari attributi, **SelectFromModel**.\n",
    "\n",
    "Questo strumento, offerto da sklearn, è di fatto un meta-trasformatore che a seconda dello stimatore che gli viene passato, va a fare una selezione delle features ad-hoc.\n",
    "In questo caso ho scelto di utilizzare la **RidgeRegression**, che è un ottimo strumento per poter andare a diminuire l'overfitting.\n",
    "\n",
    "\n",
    "L’idea alla base della Ridge Regression è quella di limitare il valore assoluto dei coefficienti **Wi** definendo come segue la funzione di costo totale (da minimizzare nella fase di training):\n",
    "\n",
    ">> $$costoRidge = misura del “fit” + misura della grandezza dei coefficienti$$\n",
    "\n",
    "Con misura del fit, che rappresenta una qualsiasi funzione di costo come per esempio l'**RSS**, mentre la grandezza dei coefficienti, per quanto riguarda la RidgeRegression, è rappresentata dall'utilizzo della **l2 norm**.\n",
    "\n",
    "La **l2 norm** è il fattore di regolarizzazione rappresentato dalla seguente espressione:\n",
    ">> $$R(W) = \\sum _l (w_l)^2$$\n",
    "\n",
    "Questo parametro di regolarizzazione va a mettere in quadratura tutti i parametri.Successivamente li vado a sommare.\n",
    "Con parametri piccoli la quadratura mi fa scendere il costo(perchè se ho valori <1, andando a fare il quadrato questi mi diventano ancora più piccoli), con parametri sopra l'1 andrà ad aumentare(perchè ovviamente il quadrato sarà un valore più grande).\n",
    "\n",
    "La Ridge può quindi essere riscritta come:\n",
    ">> $$costoRidge(w) = RSS(w) + \\lambda * R(w)$$\n",
    "\n",
    "Come si può notare, affianco alla nostra **l2 norm**, compare un parametro **lambda**. Questo parametro viene detto di tuning, e sostanzialmente serve a bilanciare quella che è l'espressione sopra descritta. **Lambda** può assumere sostanzialmente vari valori e a seconda di quelli che assume abbiamo che la nostra funzione di costo adotta un comportamento differente. Infatti:\n",
    "\n",
    "1) se lambda=0, come si può facilmente osservare abbiamo che la nostra funzione di costo ridge diventa sostanzialmente una RSS.\n",
    "\n",
    "2) se lambda invece tende ad infinito, allora abbiamo che l'intero costo mi tende ad infinito e l'unico modo per minimizzare è quello di avere W=0.\n",
    "\n",
    "Generalmente per alti valori di lambda abbiamo inoltre un alto bias e una bassa vairianza, mentre per bassi valori il viceversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso,Ridge\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#sfm=SelectFromModel(LogisticRegression(max_iter=100000, C=1000))\n",
    "sfm=SelectFromModel(Ridge(max_iter=100000, alpha= 0.001))\n",
    "sfm.fit(X, y)\n",
    "\n",
    "sfm.get_support()\n",
    "\n",
    "selected_Ridge = X.columns[(sfm.get_support())]\n",
    "\n",
    "selected_Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[selected_Ridge]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADDESTRAMENTO DEL MODELLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "tr = DecisionTreeClassifier(criterion='entropy', random_state=0, max_depth=6)\n",
    "\n",
    "\n",
    "#fit e prediction\n",
    "tr.fit(X_train, y_train)\n",
    "pred = tr.predict(X_valid)\n",
    "print('Accuracy:',accuracy_score(y_valid, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
